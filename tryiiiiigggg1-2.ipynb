{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport gc  # For garbage collection to free memory\nimport os\nimport numpy as np\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\ntf.keras.backend.clear_session()\n\n# Paths to dataset\nimage_dir_1 = '/kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_1'\nimage_dir_2 = '/kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_2'\nmetadata_file = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n\n# Load metadata\nlabels = pd.read_csv(metadata_file)\n\n# Resize to a smaller size (64x64) to save memory\nIMG_SIZE = 64\n\n# Data Generators\ndef load_and_preprocess_data(labels, image_dir_1, image_dir_2, img_size):\n    images = []\n    label_list = []\n\n    for _, row in labels.iterrows():\n        file_path_1 = os.path.join(image_dir_1, row['image_id'] + '.jpg')\n        file_path_2 = os.path.join(image_dir_2, row['image_id'] + '.jpg')\n\n        if os.path.exists(file_path_1):\n            img = Image.open(file_path_1).resize((img_size, img_size))  # Resize to img_size x img_size\n        elif os.path.exists(file_path_2):\n            img = Image.open(file_path_2).resize((img_size, img_size))\n        else:\n            continue  # Skip if file is missing\n\n        images.append(np.array(img) / 255.0)  # Normalize to [0, 1]\n        label_list.append(row['dx'])  # Append diagnosis\n\n    X = np.array(images)  # Shape: (num_samples, img_size, img_size, 3)\n    y = pd.factorize(pd.Series(label_list))[0]  # Encode labels as integers\n    y_one_hot = to_categorical(y)  # Convert labels to one-hot encoding\n    class_names = pd.factorize(pd.Series(label_list))[1]  # Class names for reference\n    return X, y_one_hot, class_names\n\n# Call the function to load data\nX, y_one_hot, class_names = load_and_preprocess_data(labels, image_dir_1, image_dir_2, IMG_SIZE)\n\n# Check memory usage\nprint(f\"Dataset size (in memory): {X.nbytes / (1024 ** 2):.2f} MB\")\n\n# Split into training and validation sets (e.g., 80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n\n# Free memory\ndel X, y_one_hot\ngc.collect()\n\nprint(\"Training set shape:\", X_train.shape)\nprint(\"Validation set shape:\", X_val.shape)\n\n# Data augmentation for memory-efficient loading\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\nval_datagen = ImageDataGenerator()\n\n# Train and validation generators\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32)\nval_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n\nprint(\"Data generators created successfully.\")\n\n# Save directory for outputs\nsave_dir = '/kaggle/working/gan_outputs/'\nos.makedirs(save_dir, exist_ok=True)\nprint(f\"All outputs will be saved in: {save_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:36:00.828555Z","iopub.execute_input":"2024-12-26T11:36:00.828970Z","iopub.status.idle":"2024-12-26T11:39:25.885337Z","shell.execute_reply.started":"2024-12-26T11:36:00.828931Z","shell.execute_reply":"2024-12-26T11:39:25.884128Z"}},"outputs":[{"name":"stdout","text":"Dataset size (in memory): 938.91 MB\nTraining set shape: (8012, 64, 64, 3)\nValidation set shape: (2003, 64, 64, 3)\nData generators created successfully.\nAll outputs will be saved in: /kaggle/working/gan_outputs/\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\n\n# Set the mixed precision policy\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n\nprint(f\"Mixed precision policy set to: {policy}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:46:28.704001Z","iopub.execute_input":"2024-12-26T11:46:28.704461Z","iopub.status.idle":"2024-12-26T11:46:28.715007Z","shell.execute_reply.started":"2024-12-26T11:46:28.704425Z","shell.execute_reply":"2024-12-26T11:46:28.713698Z"}},"outputs":[{"name":"stdout","text":"Mixed precision policy set to: <FloatDTypePolicy \"mixed_float16\">\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:46:40.204300Z","iopub.execute_input":"2024-12-26T11:46:40.204741Z","iopub.status.idle":"2024-12-26T11:46:40.215618Z","shell.execute_reply.started":"2024-12-26T11:46:40.204703Z","shell.execute_reply":"2024-12-26T11:46:40.214518Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import gc\nimport tensorflow as tf\ngc.collect()\ntf.keras.backend.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:46:54.464903Z","iopub.execute_input":"2024-12-26T11:46:54.465297Z","iopub.status.idle":"2024-12-26T11:46:54.876374Z","shell.execute_reply.started":"2024-12-26T11:46:54.465264Z","shell.execute_reply":"2024-12-26T11:46:54.875065Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nimport tensorflow as tf\n\nlatent_dim = 100\n\n# Encoder\nencoder = models.Sequential([\n    layers.Input(shape=(64, 64, 3)),\n    layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Flatten(),\n    layers.Dense(latent_dim)  # Latent representation\n])\n\n# Decoder\ndecoder = models.Sequential([\n    layers.Input(shape=(latent_dim,)),\n    layers.Dense(8 * 8 * 512),\n    layers.Reshape((8, 8, 512)),\n    layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n    layers.LeakyReLU(0.2),\n    layers.Conv2DTranspose(3, kernel_size=4, padding=\"same\", activation=\"tanh\"),\n])\n\n# Full autoencoder model\nautoencoder = models.Sequential([\n    layers.Input(shape=(64,64,3)),\n    encoder,\n    decoder\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:47:01.182327Z","iopub.execute_input":"2024-12-26T11:47:01.182709Z","iopub.status.idle":"2024-12-26T11:47:01.391227Z","shell.execute_reply.started":"2024-12-26T11:47:01.182678Z","shell.execute_reply":"2024-12-26T11:47:01.389782Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\n\nclass ThesisGANModel(tf.keras.Model):\n    def __init__(self, num_classes=7, dropout_rate=0.4):\n        \"\"\"\n        Modified deep learning model for image classification tailored to the HAM10000 dataset.\n\n        Args:\n            num_classes (int): Number of output classes.\n            dropout_rate (float): Dropout rate for regularization.\n        \"\"\"\n        super(ThesisGANModel, self).__init__()\n\n        # Layer Definitions\n        self.conv1 = tf.keras.layers.Conv2D(\n            128, kernel_size=3, strides=1, padding=\"same\", activation='relu', name=\"Conv_Layer_1\"\n        )\n        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=2, name=\"MaxPool_Layer_1\")\n        self.norm1 = tf.keras.layers.BatchNormalization(name=\"BatchNorm_Layer_1\")\n\n        self.conv2 = tf.keras.layers.Conv2D(\n            256, kernel_size=3, strides=1, padding=\"same\", activation='relu', name=\"Conv_Layer_2\"\n        )\n        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=2, name=\"MaxPool_Layer_2\")\n        self.norm2 = tf.keras.layers.BatchNormalization(name=\"BatchNorm_Layer_2\")\n\n        self.conv3 = tf.keras.layers.Conv2D(\n            512, kernel_size=3, strides=1, padding=\"same\", activation='relu', name=\"Conv_Layer_3\"\n        )\n        self.pool3 = tf.keras.layers.MaxPooling2D(pool_size=2, name=\"MaxPool_Layer_3\")\n        self.norm3 = tf.keras.layers.BatchNormalization(name=\"BatchNorm_Layer_3\")\n\n        self.flatten = tf.keras.layers.Flatten(name=\"Flatten_Layer\")\n\n        self.fc1 = tf.keras.layers.Dense(256, activation='relu', name=\"Dense_Layer_1\")\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate, name=\"Dropout_Layer_1\")\n        self.fc2 = tf.keras.layers.Dense(128, activation='relu', name=\"Dense_Layer_2\")\n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate, name=\"Dropout_Layer_2\")\n        self.fc3 = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"Output_Layer\")\n\n    def call(self, inputs):\n        \"\"\"\n        Forward pass of the model.\n        \"\"\"\n        x = self.conv1(inputs)\n        x = self.pool1(x)\n        x = self.norm1(x)\n\n        x = self.conv2(x)\n        x = self.pool2(x)\n        x = self.norm2(x)\n\n        x = self.conv3(x)\n        x = self.pool3(x)\n        x = self.norm3(x)\n\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.dropout1(x)\n        x = self.fc2(x)\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\n# Instantiate the model for HAM10000 dataset\nmodel = ThesisGANModel(num_classes=7, dropout_rate=0.4)\n\n# Initialize model by passing a dummy input\ndummy_input = tf.random.normal([1, 64, 64, 3])\n_ = model(dummy_input)\n\n# Save the model summary to a file\nwith open(\"modified_thesis_model_summary.txt\", \"w\") as f:\n    model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n\n# Print the model summary to console\nmodel.summary()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:47:23.470218Z","iopub.execute_input":"2024-12-26T11:47:23.470675Z","iopub.status.idle":"2024-12-26T11:47:23.844604Z","shell.execute_reply.started":"2024-12-26T11:47:23.470639Z","shell.execute_reply":"2024-12-26T11:47:23.843586Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"thesis_gan_model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"thesis_gan_model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Conv_Layer_1 (\u001b[38;5;33mConv2D\u001b[0m)           │ ?                      │         \u001b[38;5;34m3,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_1               │ ?                      │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Conv_Layer_2 (\u001b[38;5;33mConv2D\u001b[0m)           │ ?                      │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_2               │ ?                      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Conv_Layer_3 (\u001b[38;5;33mConv2D\u001b[0m)           │ ?                      │     \u001b[38;5;34m1,180,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_3               │ ?                      │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Flatten_Layer (\u001b[38;5;33mFlatten\u001b[0m)         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │     \u001b[38;5;34m8,388,864\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)           │ ?                      │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ ?                      │           \u001b[38;5;34m903\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Conv_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_1               │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Conv_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_2               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Conv_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ MaxPool_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ BatchNorm_Layer_3               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,905,159\u001b[0m (37.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,905,159</span> (37.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,903,367\u001b[0m (37.78 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,903,367</span> (37.78 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Generator is just the decoder part (it takes latent vector as input)\ndef build_generator(latent_dim):\n    return decoder\n\n# Discriminator\ndef build_discriminator(img_shape):\n    model = models.Sequential()\n    model.add(layers.InputLayer(shape=img_shape))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1024, activation='relu'))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    return model\n\n# Compile GAN\ndef compile_gan(generator, discriminator, latent_dim):\n    # Compile the discriminator independently\n    discriminator.trainable = True\n    discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Freeze the discriminator when training the GAN\n    discriminator.trainable = False\n\n    # Create GAN model\n    gan_input = layers.Input(shape=(latent_dim,))  # Latent vector input\n    fake_img = generator(gan_input)  # Generator takes latent vector and produces image\n    gan_output = discriminator(fake_img)  # Discriminator evaluates the generated image\n    gan = models.Model(gan_input, gan_output)\n\n    gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5), loss='binary_crossentropy')\n\n    return generator, discriminator, gan\n\n# Build and compile\ngenerator = build_generator(latent_dim)\ndiscriminator = build_discriminator((64, 64, 3))\ngenerator, discriminator, gan = compile_gan(generator, discriminator, latent_dim)\n\n# Output the shapes of the models\nprint(\"Generator Summary:\")\ngenerator.summary()\nprint(\"\\nDiscriminator Summary:\")\ndiscriminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:47:34.526225Z","iopub.execute_input":"2024-12-26T11:47:34.526661Z","iopub.status.idle":"2024-12-26T11:47:34.719575Z","shell.execute_reply.started":"2024-12-26T11:47:34.526626Z","shell.execute_reply":"2024-12-26T11:47:34.718566Z"}},"outputs":[{"name":"stdout","text":"Generator Summary:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │     \u001b[38;5;34m3,309,568\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m2,097,408\u001b[0m │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m524,416\u001b[0m │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m131,136\u001b[0m │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m3,075\u001b[0m │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,309,568</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_transpose_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,065,603\u001b[0m (23.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,065,603</span> (23.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,065,603\u001b[0m (23.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,065,603</span> (23.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nDiscriminator Summary:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │    \u001b[38;5;34m12,583,936\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,583,936</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,240,321\u001b[0m (50.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,240,321</span> (50.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m13,240,321\u001b[0m (50.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,240,321</span> (50.51 MB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\n\n# Compile Discriminator (binary crossentropy loss and Adam optimizer)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5), metrics=['accuracy'])\n\n# Compile GAN model (combined model) with the discriminator frozen\ndiscriminator.trainable = False\ngan_input = layers.Input(shape=(latent_dim,))\nfake_img = generator(gan_input)\ngan_output = discriminator(fake_img)\ngan = models.Model(gan_input, gan_output)\ngan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:47:49.022201Z","iopub.execute_input":"2024-12-26T11:47:49.023153Z","iopub.status.idle":"2024-12-26T11:47:49.044353Z","shell.execute_reply.started":"2024-12-26T11:47:49.023107Z","shell.execute_reply":"2024-12-26T11:47:49.043132Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Define the optimizer for the discriminator\nopt_disc = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n\n# Define the discriminator model (with output shape (batch_size, 7) for multi-class classification)\ndiscriminator = tf.keras.Sequential([\n    # First Conv2D layer with proper input_shape specified\n    layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n    layers.GlobalAveragePooling2D(),  # This reduces the spatial dimensions\n    layers.Dense(7, activation='softmax')  # 7 classes (use softmax for multi-class classification)\n])\n\n# Compile the discriminator model\ndiscriminator.compile(optimizer=opt_disc, loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:47:54.137097Z","iopub.execute_input":"2024-12-26T11:47:54.137527Z","iopub.status.idle":"2024-12-26T11:47:54.192502Z","shell.execute_reply.started":"2024-12-26T11:47:54.137495Z","shell.execute_reply":"2024-12-26T11:47:54.191159Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport time\nimport os\nfrom tqdm import tqdm\n\n# Ensure reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n# Loss functions\nloss_fn_auto = tf.keras.losses.MeanSquaredError()\nloss_fn_disc = tf.keras.losses.CategoricalCrossentropy()\n\n# Optimizers\nopt_autoencoder = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\nopt_disc = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n\n# Compile the autoencoder model\nautoencoder.compile(optimizer=opt_autoencoder, loss=loss_fn_auto)\n\n# Compile the discriminator model\ndiscriminator.compile(optimizer=opt_disc, loss=loss_fn_disc, metrics=['accuracy'])\n\n# Metrics storage\nautoencoder_losses_epoch = []\ndiscriminator_losses_epoch = []\ndiscriminator_acc_epoch = []\nval_autoencoder_losses_epoch = []\nval_discriminator_losses_epoch = []\nval_discriminator_acc_epoch = []\n\n# Training loop\nfor epoch in range(10):  # Adjust the range as needed\n    start_time = time.time()\n    \n    # Initialize epoch-wise metrics\n    epoch_autoencoder_losses = []\n    epoch_discriminator_losses = []\n    epoch_discriminator_acc = []\n    epoch_val_autoencoder_losses = []\n    epoch_val_discriminator_losses = []\n    epoch_val_discriminator_acc = []\n\n    print(f\"\\nEpoch {epoch + 1} Training:\")\n    for idx, (batch_real, batch_label) in enumerate(tqdm(train_generator)):\n        with tf.GradientTape(persistent=True) as tape:\n            # Forward pass through encoder-decoder (autoencoder)\n            latent_representation = encoder(batch_real)\n            generated_image = decoder(latent_representation)\n            loss_autoencoder = loss_fn_auto(batch_real, generated_image)\n\n            # Forward pass through discriminator\n            fake = tf.clip_by_value(generated_image, 0, 1)  # Normalize generated images\n            loss_disc_real = loss_fn_disc(batch_label, discriminator(batch_real))\n            loss_disc_fake = loss_fn_disc(batch_label, discriminator(fake))\n            loss_disc = (loss_disc_real + loss_disc_fake) / 2\n\n        # Apply gradients\n        grads_autoencoder = tape.gradient(loss_autoencoder, autoencoder.trainable_weights)\n        opt_autoencoder.apply_gradients(zip(grads_autoencoder, autoencoder.trainable_weights))\n\n        grads_discriminator = tape.gradient(loss_disc, discriminator.trainable_weights)\n        opt_disc.apply_gradients(zip(grads_discriminator, discriminator.trainable_weights))\n\n        # Store batch-wise metrics\n        epoch_autoencoder_losses.append(loss_autoencoder.numpy())\n        epoch_discriminator_losses.append(loss_disc.numpy())\n        epoch_discriminator_acc.append(tf.reduce_mean(\n            tf.keras.metrics.categorical_accuracy(batch_label, discriminator(fake))).numpy())\n\n        # Save generated image for visualization\n        if idx % 200 == 0:\n            img = tf.keras.preprocessing.image.array_to_img(fake[0])\n            img.save(f\"{save_dir}/generated_img_epoch_{epoch + 1}_batch_{idx}.png\")\n\n    print(f\"\\nEpoch {epoch + 1} Validation:\")\n    for val_batch_real, val_batch_label in val_generator:\n        val_latent_representation = encoder(val_batch_real)\n        val_generated_image = decoder(val_latent_representation)\n        val_loss_autoencoder = loss_fn_auto(val_batch_real, val_generated_image)\n        val_loss_disc_real = loss_fn_disc(val_batch_label, discriminator(val_batch_real))\n        val_loss_disc_fake = loss_fn_disc(val_batch_label, discriminator(val_generated_image))\n        val_loss_disc = (val_loss_disc_real + val_loss_disc_fake) / 2\n\n        # Calculate accuracy\n        val_discriminator_accuracy = tf.reduce_mean(\n            tf.keras.metrics.categorical_accuracy(val_batch_label, discriminator(val_generated_image)))\n\n        # Store validation metrics\n        epoch_val_autoencoder_losses.append(val_loss_autoencoder.numpy())\n        epoch_val_discriminator_losses.append(val_loss_disc.numpy())\n        epoch_val_discriminator_acc.append(val_discriminator_accuracy.numpy())\n\n    # Calculate epoch averages\n    avg_autoencoder_loss = np.mean(epoch_autoencoder_losses)\n    avg_discriminator_loss = np.mean(epoch_discriminator_losses)\n    avg_discriminator_acc = np.mean(epoch_discriminator_acc)\n    avg_val_autoencoder_loss = np.mean(epoch_val_autoencoder_losses)\n    avg_val_discriminator_loss = np.mean(epoch_val_discriminator_losses)\n    avg_val_discriminator_acc = np.mean(epoch_val_discriminator_acc)\n\n    autoencoder_losses_epoch.append(avg_autoencoder_loss)\n    discriminator_losses_epoch.append(avg_discriminator_loss)\n    discriminator_acc_epoch.append(avg_discriminator_acc)\n    val_autoencoder_losses_epoch.append(avg_val_autoencoder_loss)\n    val_discriminator_losses_epoch.append(avg_val_discriminator_loss)\n    val_discriminator_acc_epoch.append(avg_val_discriminator_acc)\n\n    # Print epoch metrics\n    print(f\"Epoch {epoch + 1}, Autoencoder Loss: {avg_autoencoder_loss:.6f}, \"\n          f\"Discriminator Loss: {avg_discriminator_loss:.6f}, Discriminator Accuracy: {avg_discriminator_acc:.6f}\")\n    print(f\"Validation - Autoencoder Loss: {avg_val_autoencoder_loss:.6f}, \"\n          f\"Discriminator Loss: {avg_val_discriminator_loss:.6f}, Discriminator Accuracy: {avg_val_discriminator_acc:.6f}\")\n    print(f\"Epoch {epoch + 1} took {time.time() - start_time:.2f} seconds\")\n\n# Plotting\nimport matplotlib.pyplot as plt\n\n# Autoencoder Loss\nplt.figure(figsize=(12, 6))\nplt.plot(autoencoder_losses_epoch, label='Training Autoencoder Loss')\nplt.plot(val_autoencoder_losses_epoch, label='Validation Autoencoder Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Autoencoder Loss')\nplt.legend()\nplt.savefig(f\"{save_dir}/autoencoder_loss.png\")\nplt.show()\n\n# Discriminator Loss\nplt.figure(figsize=(12, 6))\nplt.plot(discriminator_losses_epoch, label='Training Discriminator Loss')\nplt.plot(val_discriminator_losses_epoch, label='Validation Discriminator Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Discriminator Loss')\nplt.legend()\nplt.savefig(f\"{save_dir}/discriminator_loss.png\")\nplt.show()\n\n# Discriminator Accuracy\nplt.figure(figsize=(12, 6))\nplt.plot(discriminator_acc_epoch, label='Training Discriminator Accuracy')\nplt.plot(val_discriminator_acc_epoch, label='Validation Discriminator Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Discriminator Accuracy')\nplt.legend()\nplt.savefig(f\"{save_dir}/discriminator_accuracy.png\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T11:48:04.248544Z","iopub.execute_input":"2024-12-26T11:48:04.248965Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1 Training:\n","output_type":"stream"},{"name":"stderr","text":"5623it [5:04:46,  3.16s/it]                      ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"generator.save(f\"{output_dir}/generator_final.h5\")\ndiscriminator.save(f\"{output_dir}/discriminator_final.h5\")\nprint(\"Final models saved.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}